
<!DOCTYPE html>
<html>
  <meta charset="UTF-8">
  <head>
    <title>Sixth SPLICE Workshop</title>
    <link href="../cssplice.css" rel="stylesheet" type="text/css">
  </head>
  <body>
    <div id="content">
      <h1>Sixth SPLICE Workshop Proceedings</h1>
      <h2>Proceedings Citation</h2>
      <big>P. Brusilovsky, K. Koedinger, D.A. Joyner, T.W. Price.
      <i>Proceedings of SPLICE 2020 workshop Building an Infrastructure for Computer Science Education Research and Practice at Scale</i>
      at 7th ACM Conference on Learning at Scale, Aug 12, 2020, Virtual Event</big>
      
      <p><b>Organizers</b><br/>
        Peter Brusilovsky, University of Pittsburgh<br/>
        Ken Koedinger, Carnegie Mellon University<br/>
        David A. Joyner, Georgia Institute of Technology<br/>
        Thomas W. Price, North Carolina State University
      </p>
<h2>Peer Reviewed Papers</h2>

        <p>
            <b>Title</b>: <a href="proc/SPLICE_2020_LS_paper_9.pdf" target="_blank">Using Discussion Board Data to Hire Teaching Assistants</a><br/>
            <b>Authors</b>: Arnaud Deza, Haocheng Hu, Vaishvik Maisuria, Michael Liut, Andrew Petersen and Bogdan Simion<br/>
            
            <b>Abstract</b>: <small>Teaching Assistants (TAs) fill critical roles in instructional teams, spending one-on-one time with students, providing feedback, and serving a critical mentoring role. As a result, the process of selecting TAs is important, yet we often have little information when making hiring decisions. We used data collected from a course discussion board to identify which statistics are indicative of participation and which might be useful for hiring TAs. We then analyzed our past TA hires and found that there are opportunities to use discussion board metrics to increase the number of potentially qualified applicants for TA roles and better inform instructors about the engagement of past students as they select candidates for interviews.</small>
        </p>
        <p>
            <b>Title</b>: <a href="proc/SPLICE_2020_LS_paper_12.pdf" target="_blank">Custom &quot;Caring IDE&quot; for Online Offering of CS1</a><br/>
            <b>Authors</b>: Mohsen Dorodchi, Mohammadali Fallahian, Erfan Al-Hossami, Aileen Benedict and Alexandria Benedict<br/>
            
            <b>Abstract</b>: <small>The role of an integrated IDE capable of several different key features in teaching and learning programming is very clear to everyone. In this work-in-progress paper, we present the new version of our Caring IDE, a cloud-based IDE system integrated with a Learning Management System (LMS), an autograder, databases for storage, and dashboard prototypes to (1) deliver a smoother programming learning experience for students and (2) enhance the instructor&#x27;s ability to informatively perform student success interventions quickly and early. Here, we report and extrapolate on the design and implementation of the Caring IDE. We also demonstrate the value of the Caring IDE in promoting student-self learning in an online CS1 summer course during the COVID-19 pandemic. Finally, we showcase preliminary IDE-based analytics to promote student success in CS courses.</small>
        </p><h2>Peer Reviewed Lightning Talks</h2>

        <p>
            <b>Title</b>: <a href="proc/SPLICE_2020_LS_paper_2.pdf" target="_blank">Recommending Personalized Review Questions using Collaborative Filtering</a><br/>
            <b>Authors</b>: Zain Kazmi, Wafiqah Raisa, Harsh Jhunjhunwala and Lisa Zhang<br/>
            
            <b>Abstract</b>: <small>This paper presents the work in progress towards a tool where CS1 students receive personalized review questions to prepare for their term tests. Specifically, the tool recommends multiple choice and coding questions. The recommendations are generated using collaborative filtering, based on students&#x27; past performance on these questions. We test recommendation engine models based on last year&#x27;s student data, and present offline experiments that show the promise of this approach.</small>
        </p>
        <p>
            <b>Title</b>: <a href="proc/SPLICE_2020_LS_paper_3.pdf" target="_blank">CS1 Programming Feedback with Bug Localization</a><br/>
            <b>Authors</b>: Lucas Roy, Haotian Yang and Lisa Zhang<br/>
            
            <b>Abstract</b>: <small>This paper presents the work in progress towards generating automatic feedback to student solutions to CS1 coding questions that highlights regions of the code that may be problematic. We use a Recurrent Neural Network to generate such feedback. We use a data-driven approach to train the model by re-purposing past student submissions and student corrections to their own code. We present preliminary results of a model that works on one problem. We hope to eventually integrate this kind of feedback in a CS1 setting.</small>
        </p>
        <p>
            <b>Title</b>: <a href="proc/SPLICE_2020_LS_paper_4.pdf" target="_blank">TYPOS: A Computer Science Exercise Platform</a><br/>
            <b>Authors</b>: Adam Gaweda and Collin Lynch<br/>
            
            <b>Abstract</b>: <small>Computer Science has a number of exercise types available for learning. However, it is unknown when the appropriate exercise type should be given to students on their path to learning CS. This paper describes TYPOS, a Computer Science Exercise Platform that hosts a variety of exercise types. These CS exercises range in complexity and interactivity based on the ICAP framework. As part of this paper, we provide a brief overview over each exercise type and their respective complexity. Finally, we present considerations for future research on using TYPOS for activity sequence mining and suggested next practice activities for students.</small>
        </p>
        <p>
            <b>Title</b>: <a href="proc/SPLICE_2020_LS_paper_5.pdf" target="_blank">Learnersourcing at Scale for Introductory Programming: Longitudinal Data Collection on the Python Tutor Website</a><br/>
            <b>Authors</b>: Philip Guo, Julia Markel and Xiong Zhang<br/>
            
            <b>Abstract</b>: <small>The Python Tutor website (pythontutor.com) currently gets over 10,000 daily active users executing around 100,000 pieces of code daily. We have been experimenting with collecting large-scale data about learners&#x27; thought processes while coding. For instance, we created a learnersourcing system that elicits explanations of potential misconceptions from learners as they fix errors. We have deployed this system for the past three years to the Python Tutor website and collected 16,791 learner-written explanations. By inspecting this dataset, we found surprising insights that we did not originally think of due to our own expert blind spots as programming instructors. We are now using these insights to improve compiler and run-time error messages to explain common novice misconceptions.</small>
        </p>
        <p>
            <b>Title</b>: <a href="proc/SPLICE_2020_LS_paper_6.pdf" target="_blank">Database Query Analyzer Integration</a><br/>
            <b>Authors</b>: Ryan Hardt and Kamil Akhuseyinoglu<br/>
            
            <b>Abstract</b>: <small>This paper describes updates to Database Query Analyzer (DBQA) that increase its interoperability with other learning tools using the Learning Tools Interoperability (LTI) protocol. As a result, DBQA has been integrated with Mastery Grids and allows for integration with learning management systems.</small>
        </p>
        <p>
            <b>Title</b>: <a href="proc/SPLICE_2020_LS_paper_7.pdf" target="_blank">Live Catalog of Smart Learning Objects for Computer Science Education</a><br/>
            <b>Authors</b>: Alexander Hicks, Kamil Akhuseyinoglu, Clifford Shaffer and Peter Brusilovsky<br/>
            
            <b>Abstract</b>: <small>We present the initial version of a &quot;live catalog&quot; of LTI enabled smart learning objects that instructors and educators are able to preview and test before deciding whether to integrate these tools in their own courses. The catalog is available on the public Instructure Canvas site and currently showcases LTI tools from multiple educational institutions.</small>
        </p>
        <p>
            <b>Title</b>: <a href="proc/SPLICE_2020_LS_paper_8.pdf" target="_blank">Making it Smart: Converting Static Code into an Interactive Trace Table</a><br/>
            <b>Authors</b>: Zak Risha and Peter Brusilovsky<br/>
            
            <b>Abstract</b>: <small>This paper introduces a new type of smart learning content, an automatically generated trace table, that can easily integrate and adapt to existing curriculum and learning systems for computer science education. In addition to current features of the software, we describe how this tool constructs trace tables using only source code as an input. The potential of this tool is also explored by examining future opportunities in adaptation, feedback, and learning specifications. Last, we report a pilot integration into an existing system to demonstrate interoperability with a tangible use case.</small>
        </p>
        <p>
            <b>Title</b>: <a href="proc/SPLICE_2020_LS_paper_11.pdf" target="_blank">Runestone: An Open-Source Platform for Interactive Ebooks</a><br/>
            <b>Authors</b>: Barbara Ericson and Bradley Miller<br/>
            
            <b>Abstract</b>: <small>The Runestone platform is an open-source platform for interactive ebooks. It served over 100,000 registered learners and an average of 800 thousand page views per week during the 2019 - 2020 academic year. There are ebooks for secondary computer science as well as for undergraduate computing courses: CS1, CS2, data science, and web programming. There is even an ebook for a course on Linear Algebra. The platform supports executable and editable examples in Python, Java, C, C++, HTML, JavaScript, Processing, and SQL. It also includes code visualizers/steppers for Python, Java, and C++ code. The ebooks contain typical instructional material: text, videos, and images. They also include practice problems with immediate feedback such as multiple-choice, fill-in-the-blank, and matching questions. Runestone also has unusual features such as audio tours of code, clickable areas, adaptive Parsons problems, and a unique practice tool. This paper highlights some of the unusual features, explains the log data that is collected and is available for analysis, and describes plans for future development.</small>
        </p>
    </div>
    <div id="footer">
      <p class="footertext">
        Last updated:
        <script type="text/javascript">
          document.write(document.lastModified);
        </script>
      </p>
    </div>

  </body>
</html>
